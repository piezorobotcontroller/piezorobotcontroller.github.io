<!DOCTYPE HTML>
<html>
    <head>
        <title>Model-Based Control of Planar Piezoelectric Inchworm Soft Robot for Crawling in Constrained Environments</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-MD9TTXQ63J"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-MD9TTXQ63J');
        </script>
    </head>
    <body id="body">
        <div id="main"> 
            <header id="header">
            </header>
            <!-- style="padding-bottom:1em" -->
            <div id="profile">
                <!-- <img src="images/profile.jpg"> -->
                <div id="profile-desc">
                    <div id="profile-name">Model-Based Control of Planar Piezoelectric Inchworm Soft Robot for Crawling in Constrained Environments
                        <p><br>2022 IEEE 5th International Conference on Soft Robotics (RoboSoft)</p>
                    </div>
                    <p>
                    <b>Abstract</b>. Soft robots have drawn significant attention recently for their ability to achieve rich shapes when interacting with complex environments. However, their elasticity and flexibility compared to rigid robots also pose significant challenges for precise and robust shape control in real-time. Motivated by their potential to operate in highly-constrained environments, as in search-and-rescue operations, this work addresses these challenges of soft-robots by developing a model-based full-shape controller, validated and demonstrated by experiments. A five-actuator planar soft robot was constructed with planar piezoelectric layers bonded to a steel foil substrate, enabling inchworm-like motion. The controller uses a soft-body continuous model for shape planning and control, given target shapes and/or environmental constraints, such as crawling under overhead barriers or "roof" safety lines. An approach to background model calibrations is developed to address deviations of actual robot shape due to material parameter variations and drift. Full experimental shape control and optimal movement under a roof safety line are demonstrated, where the robot maximizes its speed within the overhead constraint. The mean-squared error between the measured and target shapes improves from ~0.05 cm<sup>2</sup> without calibration to ~0.01 cm<sup>2</sup> with calibration. Simulation-based validation is also performed with various different roof shapes. </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            <div class="section recent-work">
                <!-- <h1>Highlights</h1> -->
                <div class="highlight-proj">
                    <!-- <a href="http://arc.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/sim-pushing-piles.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Pushing piles with closed-loop feedback</p>
                </div>
                <div class="highlight-proj">
                    <!-- <a href="http://tossingbot.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/real-assemble-kit.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Production pick-and-place w/o 3D models</p>
                </div>
                <div class="highlight-proj">
                    <!-- <a href="http://tossingbot.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/sim-hanoi.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Multi-step sequential tasks</p>
                </div>
            </div>
            <!-- <div class="divider"></div> -->
            <div class="section recent-work">
                <!-- <div class="highlight-proj">
                    <video playsinline="" muted="" autoplay="" loop="">
                        <source src="images/real-data-collection.mp4" type="video/mp4">
                    </video><p>Data collection UI</p>
                </div> -->
                <div class="highlight-proj">
                    <video playsinline="" muted="" autoplay="" loop="">
                        <source src="images/sim-unseen-kit.mp4" type="video/mp4">
                    </video><p>Pick-and-place with unseen objects</p>
                </div>
                <div class="highlight-proj">
                    <!-- <a href="https://graspinwild.cs.columbia.edu/"> --><video playsinline="" muted="" autoplay="" loop="">
                        <source src="images/sweeping.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Learning to push piles on real robots</p>
                </div>
                <div class="highlight-proj">
                    <!-- <a href="http://arc.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/real-stack-plates.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Pick-conditioned placing from 10 examples</p>
                </div>
            </div>      
            <div class="divider"></div>  
            <div class="section paper">
                <h1>Paper</h1>
                <p>Latest version (Mar 28, 2022): <a href="https://arxiv.org/abs/2010.14406">arXiv:2010.14406 [cs.RO]</a>.<br>
                  Published at the 2022 IEEE 5th International Conference on Soft Robotics (RoboSoft)<br>
                <a href="https://arxiv.org/pdf/2010.14406.pdf"><img src="images/thumbnail-half.jpg"></a>
            </div>
            <div class="divider"></div>
            <div class="section paper half">
                <h1>Code</h1>
                <p>
                    Code is available on <a href="https://github.com/google-research/ravens">Github</a>. Includes:<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;Simulation environments (Ravens with PyBullet).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;Training/testing code (with TensorFlow/Python).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;Pre-trained models and datasets.<br><br>
                    Simple toy examples with JAX and Flax in <a href="https://colab.research.google.com/drive/13VTA8nLM8AuzXuygQA1X_KWzLLxVPJhM?usp=sharing">Colab</a>.<br>
                </p>

            </div>
            <div class="section bibtex half">
                <h1>Bibtex</h1>
                <div class="code">@article{zeng2020transporter,<br>
&nbsp;&nbsp;&nbsp;&nbsp;title={Transporter Networks: Rearranging the Visual World for Robotic Manipulation},<br>
&nbsp;&nbsp;&nbsp;&nbsp;author={Zeng, Andy and Florence, Pete and Tompson, Jonathan and Welker, Stefan and Chien, Jonathan and Attarian, Maria and Armstrong, Travis and Krasin, Ivan and Duong, Dan and Sindhwani, Vikas and Lee, Johnny},<br>
&nbsp;&nbsp;&nbsp;&nbsp;journal={Conference on Robot Learning (CoRL)},<br>
&nbsp;&nbsp;&nbsp;&nbsp;year={2020}<br>
}</div>
            </div>    
            <div class="divider"></div>
            <div class="section team">
                <h1>Team</h1>
                <div class="people-profile">
                    <a href="https://sites.google.com/view/zhiwuzheng/"><img src="images/people/zhiwu.jpeg"><p>Zhiwu Zheng</p>
                    </a>
                </div>
                <div class="people-profile">
                    <a><img src="images/people/prakhar.jpg"><p>Prakhar Kumar</p>
                    </a>
                </div>
                <div class="people-profile">
                    <a><img src="images/people/yenan.jpeg"><p>Yenan Chen</p>
                    </a>
                </div>
                <div class="people-profile">
                    <a><img src="images/people/hsin.jpg"><p>Hsin Cheng</p>
                    </a>
                </div>
               
                <div class="people-profile">
                    <a><img src="images/people/sigurd.png"><p>Sigurd Wagner</p>
                    </a>
                </div>
                <div class="people-profile">
                    <a href="https://www.princeton.edu/~minjie/"><img src="images/people/minjie.jpeg"><p>Minjie Chen</p>
                    </a>
                </div>
                <div class="people-profile">
                    <a href="https://nverma.princeton.edu/"><img src="images/people/naveen.jpeg"><p>Naveen Verma</p>
                    </a>
                </div>
                <div class="people-profile">
                    <a href="https://scholar.princeton.edu/sturm/"><img src="images/people/james.jpeg"><p>James C. Sturm&nbsp;</p>
                    </a>
                </div>
               
                <div style="clear: both;"></div>
            </div>
			<img style="height: 80px; margin-left: 30px; margin-bottom: 10px" src="images/PU-standard.png">
            <div style="clear: both;"></div>
            <div class="divider"></div>  
            <div class="section video">
                <h1>Plenary Talk</h1>
                <p>Watch it on YouTube (<a href="https://youtu.be/8afHfReCfPo?t=12214">link</a>)<br><a href="https://youtu.be/8afHfReCfPo?t=12214"><img src="images/talk-thumbnail.png" width="640px" style="border: 2px solid #191e3f; margin-top: 10px"></a></p>
            </div>
            <div class="section video">
                <h1>Supplemental Video</h1>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/496UVuAdOP4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
            <div class="section video">
                <h1>Method</h1>
                <video style="margin-left: 30px; width: 480px; margin-bottom: 30px" playsinline="" muted="" autoplay="" loop="">
                    <source src="images/animation.mp4" type="video/mp4">
                </video>
            </div>
            <div class="divider"></div>
            
            <div class="section acknowledgements">
                <h1>Acknowledgements</h1>
                <p>This work was supported by the Semiconductor Research Corporation (SRC), DARPA, Princeton Program in Plasma Science and Technology, and Princeton University.</p>
                <br><br>
            </div>
            <br><br><br><br><br><br><br><br><br><br>
            <div class="divider"></div>
        </div>
    </body>
</html>
